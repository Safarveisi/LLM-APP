{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "from typing import Tuple, List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from haystack.utils import Secret\n",
    "from haystack import Pipeline\n",
    "\n",
    "from haystack.dataclasses import Document\n",
    "\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.retrievers import InMemoryEmbeddingRetriever\n",
    "from haystack.document_stores.types import DuplicatePolicy\n",
    "from haystack.utils import ComponentDevice\n",
    "\n",
    "from haystack.evaluation.eval_run_result import EvaluationRunResult\n",
    "\n",
    "from haystack.components.builders import PromptBuilder, AnswerBuilder\n",
    "from haystack.components.joiners import DocumentJoiner\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.evaluators import (\n",
    "    FaithfulnessEvaluator,\n",
    "    ContextRelevanceEvaluator,\n",
    ")\n",
    "\n",
    "from haystack.components.fetchers.link_content import LinkContentFetcher\n",
    "from haystack.components.converters import HTMLToDocument, PyPDFToDocument\n",
    "from haystack.components.preprocessors import DocumentSplitter, DocumentCleaner\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.embedders import (\n",
    "    SentenceTransformersDocumentEmbedder,\n",
    "    SentenceTransformersTextEmbedder,\n",
    ")\n",
    "\n",
    "from mlflow.metrics.genai.metric_definitions import relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"mlflow\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI = \"http://127.0.0.1:8080\"\n",
    "# Do not use the proxy for local addresses\n",
    "os.environ[\"NO_PROXY\"] = \"127.0.0.1\"  # Comment this line if you are not using any proxy\n",
    "# Set the mlflow tracking server (assuming that the server is running locally)\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need a paid OPENAI API KEY\n",
    "OPENAI_API_KEY = getpass(\"OPENAI_API_KEY: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_database(urls: List[str], split_length: int) -> InMemoryDocumentStore:\n",
    "    \"\"\"\n",
    "    Creates the vector database (persisted) for the RAG system.\n",
    "    It creates documents from html byte\n",
    "    streams from user-defined web pages.\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    An instance of a vector database\n",
    "    \"\"\"\n",
    "    # In-memory document store\n",
    "    document_store = InMemoryDocumentStore()\n",
    "    # Pipeline components to create the vector database\n",
    "    fetcher = LinkContentFetcher()\n",
    "    html_converter = HTMLToDocument()\n",
    "    cleaner = DocumentCleaner()\n",
    "    ## Overlapping chunks helps preserving contextual integrity\n",
    "    splitter = DocumentSplitter(\n",
    "        split_by=\"word\", split_length=split_length, split_overlap=16\n",
    "    )\n",
    "    # Document Embedder (sentence transformer)\n",
    "    document_embedder = SentenceTransformersDocumentEmbedder(\n",
    "        model=\"BAAI/bge-large-en-v1.5\",  # Check the hugging face website for more info about the transformer\n",
    "        device=ComponentDevice.from_str(\n",
    "            \"cuda:0\"\n",
    "        ),  # Replace cuda:0 with cpu if GPU is not available\n",
    "    )\n",
    "    ## Download the model\n",
    "    document_embedder.warm_up()\n",
    "    ## Writes documents and their embeddings into the vector database\n",
    "    writer = DocumentWriter(document_store=document_store, policy=DuplicatePolicy.SKIP)\n",
    "\n",
    "    ## Pipeline\n",
    "    indexing_pipeline = Pipeline()\n",
    "\n",
    "    # Adding components into the pipeline\n",
    "    indexing_pipeline.add_component(instance=fetcher, name=\"fetcher\")\n",
    "    indexing_pipeline.add_component(instance=html_converter, name=\"html_converter\")\n",
    "    indexing_pipeline.add_component(instance=cleaner, name=\"cleaner\")\n",
    "    indexing_pipeline.add_component(instance=splitter, name=\"splitter\")\n",
    "    indexing_pipeline.add_component(\n",
    "        instance=document_embedder, name=\"document_embedder\"\n",
    "    )\n",
    "    indexing_pipeline.add_component(instance=writer, name=\"writer\")\n",
    "\n",
    "    ## Pipeline connections\n",
    "    indexing_pipeline.connect(\"fetcher.streams\", \"html_converter.sources\")\n",
    "    indexing_pipeline.connect(\"html_converter.documents\", \"cleaner\")\n",
    "    indexing_pipeline.connect(\"cleaner\", \"splitter\")\n",
    "    indexing_pipeline.connect(\"splitter\", \"document_embedder\")\n",
    "    indexing_pipeline.connect(\"document_embedder\", \"writer.documents\")\n",
    "\n",
    "    ## Write the html byte streams into the vector database\n",
    "    indexing_pipeline.run(data={\"fetcher\": {\"urls\": urls}})\n",
    "\n",
    "    return document_store\n",
    "\n",
    "\n",
    "def create_rag_pipeline(document_store: InMemoryDocumentStore) -> Pipeline:\n",
    "    \"\"\"\n",
    "    Creates a RAG pipeline using an in-memory vector database.\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    document_store:\n",
    "        An instance of a document store\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    An instance of a Pipeline (RAG)\n",
    "    \"\"\"\n",
    "    # Create the prompt for the LLM (generative model)\n",
    "    prompt_template = \"\"\"\n",
    "    Answer the following question given the documents.\n",
    "    If the answer is not contained within the documents reply with 'no_answer'. \n",
    "    Your answer should not exceed 100 words. \n",
    "    Query: {{question}}\n",
    "    Documents:\n",
    "    {% for document in documents %}\n",
    "    {{document.content}}\n",
    "    {% endfor %}\n",
    "    \"\"\"\n",
    "\n",
    "    # Pipeline components for RAG\n",
    "    prompt_builder = PromptBuilder(template=prompt_template)\n",
    "    text_embedder = SentenceTransformersTextEmbedder(\n",
    "        model=\"BAAI/bge-large-en-v1.5\", device=ComponentDevice.from_str(\"cuda:0\")\n",
    "    )\n",
    "    retriever = InMemoryEmbeddingRetriever(document_store)\n",
    "    llm = OpenAIGenerator(\n",
    "        model=\"gpt-4o-mini\", api_key=Secret.from_token(OPENAI_API_KEY)\n",
    "    )\n",
    "\n",
    "    ## Pipeline\n",
    "    rag_pipeline = Pipeline()\n",
    "\n",
    "    ## Adding components into the pipeline\n",
    "    rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "    rag_pipeline.add_component(\"retriever\", retriever)\n",
    "    rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "    rag_pipeline.add_component(\"llm\", llm)\n",
    "    rag_pipeline.add_component(\"answer_builder\", AnswerBuilder())\n",
    "\n",
    "    ## Pipeline connections\n",
    "    rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "    rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "    rag_pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "    rag_pipeline.connect(\"llm.replies\", \"answer_builder.replies\")\n",
    "    rag_pipeline.connect(\"llm.meta\", \"answer_builder.meta\")\n",
    "    rag_pipeline.connect(\"retriever\", \"answer_builder.documents\")\n",
    "\n",
    "    return rag_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://mlflow.org/docs/latest/index.html\",\n",
    "    \"https://mlflow.org/docs/latest/tracking/autolog.html\",\n",
    "    \"https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html\",\n",
    "    \"https://mlflow.org/docs/latest/python_api/mlflow.deployments.html\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = pd.DataFrame(\n",
    "    {\n",
    "        \"question\": [\n",
    "            \"What is MLflow?\",\n",
    "            \"What is Databricks?\",\n",
    "            \"How to serve a model on Databricks?\",\n",
    "            \"How to enable MLflow Autologging for my workspace by default?\",\n",
    "        ],\n",
    "        \"source\": [\n",
    "            [\"https://mlflow.org/docs/latest/index.html\"],\n",
    "            [\n",
    "                \"https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html\"\n",
    "            ],\n",
    "            [\"https://mlflow.org/docs/latest/python_api/mlflow.deployments.html\"],\n",
    "            [\"https://mlflow.org/docs/latest/tracking/autolog.html\"],\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/227213818757815639', creation_time=1725017666836, experiment_id='227213818757815639', last_update_time=1725017666836, lifecycle_stage='active', name='Evaluate Split Length', tags={}>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Evaluate Split Length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_split_length(split_length: int) -> \"Evaluation\":\n",
    "\n",
    "    document_store = create_vector_database(urls=urls, split_length=split_length)\n",
    "    rag_pipeline = create_rag_pipeline(document_store=document_store)\n",
    "\n",
    "    def extract_source(doc: Document) -> str:\n",
    "        if \"url\" in doc.meta:\n",
    "            return doc.meta[\"url\"]\n",
    "        else:\n",
    "            raise KeyError(\"'url' key does not exist in the metadata\")\n",
    "\n",
    "    def retrieve_doc_sources(question: str) -> List[str]:\n",
    "        response = rag_pipeline.run(\n",
    "            {\n",
    "                \"text_embedder\": {\"text\": question},\n",
    "                \"prompt_builder\": {\"question\": question},\n",
    "                \"answer_builder\": {\"query\": question},\n",
    "            }\n",
    "        )\n",
    "        docs = response[\"answer_builder\"][\"answers\"][0].documents\n",
    "        return [extract_source(doc) for doc in docs]\n",
    "\n",
    "    def retriever_model_function(question_df: pd.DataFrame) -> pd.Series:\n",
    "        return question_df[\"question\"].apply(retrieve_doc_sources)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        return mlflow.evaluate(\n",
    "            model=retriever_model_function,\n",
    "            data=eval_data,\n",
    "            model_type=\"retriever\",\n",
    "            targets=\"source\",\n",
    "            evaluators=\"default\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a1a13e020a4c20901af5133a1b3007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb825f6bb034cb8a12154d08f22d9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d49216b92f24f6daed641fc5b194cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814377bcace94ec6802fcc23e300a325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e6b4c6af5c4d8ea7b999489aa528d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7ce226a66048eab21a0c085ef06e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acca72de85e548f399e0b309ea246647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142d7f2edd13490f8305030f183d06b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084f07627c8c4c69b44179a1d82b3ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4999f59655644edf86154aff42eb1c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result1 = evaluate_split_length(1000)\n",
    "result2 = evaluate_split_length(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd3a547f1c64efc8a3b9bc66cbf51b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>source</th>\n",
       "      <th>outputs</th>\n",
       "      <th>precision_at_3/score</th>\n",
       "      <th>recall_at_3/score</th>\n",
       "      <th>ndcg_at_3/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is MLflow?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/index.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/index.html, ht...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Databricks?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/getting-starte...</td>\n",
       "      <td>[https://mlflow.org/docs/latest/python_api/mlf...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.63093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to serve a model on Databricks?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/python_api/mlf...</td>\n",
       "      <td>[https://mlflow.org/docs/latest/python_api/mlf...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to enable MLflow Autologging for my worksp...</td>\n",
       "      <td>[https://mlflow.org/docs/latest/tracking/autol...</td>\n",
       "      <td>[https://mlflow.org/docs/latest/tracking/autol...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                                    What is MLflow?   \n",
       "1                                What is Databricks?   \n",
       "2                How to serve a model on Databricks?   \n",
       "3  How to enable MLflow Autologging for my worksp...   \n",
       "\n",
       "                                              source  \\\n",
       "0        [https://mlflow.org/docs/latest/index.html]   \n",
       "1  [https://mlflow.org/docs/latest/getting-starte...   \n",
       "2  [https://mlflow.org/docs/latest/python_api/mlf...   \n",
       "3  [https://mlflow.org/docs/latest/tracking/autol...   \n",
       "\n",
       "                                             outputs  precision_at_3/score  \\\n",
       "0  [https://mlflow.org/docs/latest/index.html, ht...              0.333333   \n",
       "1  [https://mlflow.org/docs/latest/python_api/mlf...              0.333333   \n",
       "2  [https://mlflow.org/docs/latest/python_api/mlf...              0.666667   \n",
       "3  [https://mlflow.org/docs/latest/tracking/autol...              0.666667   \n",
       "\n",
       "   recall_at_3/score  ndcg_at_3/score  \n",
       "0                  1          1.00000  \n",
       "1                  1          0.63093  \n",
       "2                  1          1.00000  \n",
       "3                  1          1.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e735c2c6ce4472975fb1432c186cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>source</th>\n",
       "      <th>outputs</th>\n",
       "      <th>precision_at_3/score</th>\n",
       "      <th>recall_at_3/score</th>\n",
       "      <th>ndcg_at_3/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is MLflow?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/index.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/index.html, ht...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Databricks?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/getting-starte...</td>\n",
       "      <td>[https://mlflow.org/docs/latest/python_api/mlf...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.63093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to serve a model on Databricks?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/python_api/mlf...</td>\n",
       "      <td>[https://mlflow.org/docs/latest/python_api/mlf...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to enable MLflow Autologging for my worksp...</td>\n",
       "      <td>[https://mlflow.org/docs/latest/tracking/autol...</td>\n",
       "      <td>[https://mlflow.org/docs/latest/tracking/autol...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                                    What is MLflow?   \n",
       "1                                What is Databricks?   \n",
       "2                How to serve a model on Databricks?   \n",
       "3  How to enable MLflow Autologging for my worksp...   \n",
       "\n",
       "                                              source  \\\n",
       "0        [https://mlflow.org/docs/latest/index.html]   \n",
       "1  [https://mlflow.org/docs/latest/getting-starte...   \n",
       "2  [https://mlflow.org/docs/latest/python_api/mlf...   \n",
       "3  [https://mlflow.org/docs/latest/tracking/autol...   \n",
       "\n",
       "                                             outputs  precision_at_3/score  \\\n",
       "0  [https://mlflow.org/docs/latest/index.html, ht...              0.333333   \n",
       "1  [https://mlflow.org/docs/latest/python_api/mlf...              0.333333   \n",
       "2  [https://mlflow.org/docs/latest/python_api/mlf...              0.666667   \n",
       "3  [https://mlflow.org/docs/latest/tracking/autol...              0.333333   \n",
       "\n",
       "   recall_at_3/score  ndcg_at_3/score  \n",
       "0                  1          1.00000  \n",
       "1                  1          0.63093  \n",
       "2                  1          1.00000  \n",
       "3                  1          1.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(result1.tables[\"eval_results_table\"])\n",
    "display(result2.tables[\"eval_results_table\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the RAG system for its relevancy and latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/464488942055089167', creation_time=1725054362749, experiment_id='464488942055089167', last_update_time=1725054362749, lifecycle_stage='active', name='Evaluate Latency and relevance', tags={}>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Evaluate Latency and relevance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(\n",
    "    {\n",
    "        \"questions\": [\n",
    "            \"What is MLflow?\",\n",
    "            \"What is Databricks?\",\n",
    "            \"How to serve a model on Databricks?\",\n",
    "            \"How to enable MLflow Autologging for my workspace by default?\",\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is MLflow?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Databricks?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to serve a model on Databricks?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to enable MLflow Autologging for my worksp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions\n",
       "0                                    What is MLflow?\n",
       "1                                What is Databricks?\n",
       "2                How to serve a model on Databricks?\n",
       "3  How to enable MLflow Autologging for my worksp..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35bfb39fe14410ba24ddf0bcc9543fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store = create_vector_database(urls=urls, split_length=253)\n",
    "rag_pipeline = create_rag_pipeline(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa(question: str) -> dict:\n",
    "    out = {}\n",
    "    response = rag_pipeline.run(\n",
    "        {\n",
    "            \"text_embedder\": {\"text\": question},\n",
    "            \"prompt_builder\": {\"question\": question},\n",
    "            \"answer_builder\": {\"query\": question},\n",
    "        }\n",
    "    )[\"answer_builder\"][\"answers\"][0]\n",
    "    out[\"result\"] = response.data\n",
    "    out[\"source_documents\"] = [doc.content for doc in response.documents]\n",
    "    return out\n",
    "\n",
    "\n",
    "def model(input_df):\n",
    "    return input_df[\"questions\"].map(qa).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the env variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "# Judge model for relevance\n",
    "judge_model_uri = \"openai:/gpt-4o-mini\"\n",
    "relevance_metric = relevance(model=judge_model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ac44ff24bb4f50bd48d50eb4e51d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7890874b02d34088ae5eb2907f186047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d662b9384d1d4dc6b051944414555361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ebc9890db34b02a04162fe85da3730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c846916259a049048c6f9d1f6d7f0414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b04b8b09a646b8bc632ce70a981cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latency/mean': 1.5651635527610779, 'latency/variance': 0.10542284979147709, 'latency/p90': 1.9355256319046021, 'relevance/v1/mean': 5.0, 'relevance/v1/variance': 0.0, 'relevance/v1/p90': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d52edb04db41b1a9ef66a39a4cba35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99cf63ed80c4af186cb866780f9d159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>outputs</th>\n",
       "      <th>source_documents</th>\n",
       "      <th>latency</th>\n",
       "      <th>token_count</th>\n",
       "      <th>relevance/v1/score</th>\n",
       "      <th>relevance/v1/justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is MLflow?</td>\n",
       "      <td>MLflow is an open-source platform designed to ...</td>\n",
       "      <td>[MLflow: A Tool for Managing the Machine Learn...</td>\n",
       "      <td>1.242014</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>The output comprehensively answers the questio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Databricks?</td>\n",
       "      <td>Databricks is a cloud-based platform designed ...</td>\n",
       "      <td>[get_deploy_client client = get_deploy_client(...</td>\n",
       "      <td>1.293358</td>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>The output comprehensively answers the questio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to serve a model on Databricks?</td>\n",
       "      <td>To serve a model on Databricks, use MLflow to ...</td>\n",
       "      <td>[enterprise user and willing to productionize ...</td>\n",
       "      <td>1.680429</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>The output comprehensively addresses the quest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to enable MLflow Autologging for my worksp...</td>\n",
       "      <td>To enable MLflow autologging by default for yo...</td>\n",
       "      <td>[Automatic Logging with MLflow Tracking\\nAuto ...</td>\n",
       "      <td>2.044853</td>\n",
       "      <td>106</td>\n",
       "      <td>5</td>\n",
       "      <td>The output directly addresses the question abo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0                                    What is MLflow?   \n",
       "1                                What is Databricks?   \n",
       "2                How to serve a model on Databricks?   \n",
       "3  How to enable MLflow Autologging for my worksp...   \n",
       "\n",
       "                                             outputs  \\\n",
       "0  MLflow is an open-source platform designed to ...   \n",
       "1  Databricks is a cloud-based platform designed ...   \n",
       "2  To serve a model on Databricks, use MLflow to ...   \n",
       "3  To enable MLflow autologging by default for yo...   \n",
       "\n",
       "                                    source_documents   latency  token_count  \\\n",
       "0  [MLflow: A Tool for Managing the Machine Learn...  1.242014           66   \n",
       "1  [get_deploy_client client = get_deploy_client(...  1.293358           98   \n",
       "2  [enterprise user and willing to productionize ...  1.680429          105   \n",
       "3  [Automatic Logging with MLflow Tracking\\nAuto ...  2.044853          106   \n",
       "\n",
       "   relevance/v1/score                         relevance/v1/justification  \n",
       "0                   5  The output comprehensively answers the questio...  \n",
       "1                   5  The output comprehensively answers the questio...  \n",
       "2                   5  The output comprehensively addresses the quest...  \n",
       "3                   5  The output directly addresses the question abo...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    results = mlflow.evaluate(\n",
    "        model,\n",
    "        eval_df,\n",
    "        model_type=\"question-answering\",\n",
    "        evaluators=\"default\",\n",
    "        predictions=\"result\",\n",
    "        extra_metrics=[relevance_metric, mlflow.metrics.latency()],\n",
    "        evaluator_config={\n",
    "            \"col_mapping\": {\n",
    "                \"inputs\": \"questions\",\n",
    "                \"context\": \"source_documents\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "    print(results.metrics)\n",
    "\n",
    "display(results.tables[\"eval_results_table\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
