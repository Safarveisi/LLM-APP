{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "from typing import Tuple, List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from haystack.utils import Secret\n",
    "from haystack import Pipeline\n",
    "\n",
    "from haystack.dataclasses import Document\n",
    "\n",
    "from haystack_integrations.document_stores.qdrant import QdrantDocumentStore\n",
    "from haystack_integrations.components.retrievers.qdrant import QdrantEmbeddingRetriever\n",
    "from haystack.document_stores.types import DuplicatePolicy\n",
    "from haystack.utils import ComponentDevice\n",
    "\n",
    "from haystack.evaluation.eval_run_result import EvaluationRunResult\n",
    "\n",
    "from haystack.components.builders import PromptBuilder, AnswerBuilder\n",
    "from haystack.components.joiners import DocumentJoiner\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.evaluators import (\n",
    "    FaithfulnessEvaluator,\n",
    "    ContextRelevanceEvaluator,\n",
    ")\n",
    "\n",
    "from haystack.components.fetchers.link_content import LinkContentFetcher\n",
    "from haystack.components.converters import HTMLToDocument, PyPDFToDocument\n",
    "from haystack.components.preprocessors import DocumentSplitter, DocumentCleaner\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.embedders import (\n",
    "    SentenceTransformersDocumentEmbedder,\n",
    "    SentenceTransformersTextEmbedder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"mlflow\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI = \"http://127.0.0.1:8080\"\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need a paid OPENAI API KEY\n",
    "OPENAI_API_KEY = getpass(\"OPENAI_API_KEY: \", stream=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_database() -> QdrantDocumentStore:\n",
    "    \"\"\"\n",
    "    Creates the vector database (persisted) for the RAG system.\n",
    "    It creates documents from a prespecified PDF file and html byte\n",
    "    streams from some preselected web pages.\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    An instance of a vector database\n",
    "    \"\"\"\n",
    "    # Persisted document store\n",
    "    document_store = QdrantDocumentStore(\n",
    "        path=os.path.join(os.getcwd(), \"vd\"),\n",
    "        index=\"Document\",\n",
    "        recreate_index=False,\n",
    "        embedding_dim=384,  # The document embedder (below) produces dense vectors of dimensionality 384\n",
    "    )\n",
    "    # Pipeline components to create the vector database\n",
    "    fetcher = LinkContentFetcher()\n",
    "    html_converter = HTMLToDocument()\n",
    "    pdf_converter = PyPDFToDocument()\n",
    "    document_joiner = DocumentJoiner()\n",
    "    cleaner = DocumentCleaner()\n",
    "    ## Overlapping chunks helps preserving contextual integrity\n",
    "    splitter = DocumentSplitter(split_by=\"word\", split_length=256, split_overlap=16)\n",
    "    # Document Embedder (sentence transformer)\n",
    "    document_embedder = SentenceTransformersDocumentEmbedder(\n",
    "        model=\"BAAI/bge-small-en-v1.5\",  # Check the hugging face website for more info about the transformer\n",
    "        device=ComponentDevice.from_str(\n",
    "            \"cuda:0\"\n",
    "        ),  # Replace cuda:0 with cpu if GPU is not available\n",
    "    )\n",
    "    ## Download the model\n",
    "    document_embedder.warm_up()\n",
    "    ## Writes documents and their embeddings into the vector database\n",
    "    writer = DocumentWriter(document_store=document_store, policy=DuplicatePolicy.SKIP)\n",
    "\n",
    "    ## Pipeline\n",
    "    indexing_pipeline = Pipeline()\n",
    "\n",
    "    # Adding components into the pipeline\n",
    "    indexing_pipeline.add_component(instance=fetcher, name=\"fetcher\")\n",
    "    indexing_pipeline.add_component(instance=html_converter, name=\"html_converter\")\n",
    "    indexing_pipeline.add_component(instance=pdf_converter, name=\"pdf_converter\")\n",
    "    indexing_pipeline.add_component(instance=document_joiner, name=\"document_joiner\")\n",
    "    indexing_pipeline.add_component(instance=cleaner, name=\"cleaner\")\n",
    "    indexing_pipeline.add_component(instance=splitter, name=\"splitter\")\n",
    "    indexing_pipeline.add_component(\n",
    "        instance=document_embedder, name=\"document_embedder\"\n",
    "    )\n",
    "    indexing_pipeline.add_component(instance=writer, name=\"writer\")\n",
    "\n",
    "    ## Pipeline connections\n",
    "    indexing_pipeline.connect(\"fetcher.streams\", \"html_converter.sources\")\n",
    "    indexing_pipeline.connect(\"html_converter\", \"document_joiner\")\n",
    "    indexing_pipeline.connect(\"pdf_converter\", \"document_joiner\")\n",
    "    indexing_pipeline.connect(\"document_joiner.documents\", \"cleaner\")\n",
    "    indexing_pipeline.connect(\"cleaner\", \"splitter\")\n",
    "    indexing_pipeline.connect(\"splitter\", \"document_embedder\")\n",
    "    indexing_pipeline.connect(\"document_embedder\", \"writer.documents\")\n",
    "\n",
    "    ## Write the html byte streams and the pdf into the vector database\n",
    "    indexing_pipeline.run(\n",
    "        data={\n",
    "            \"fetcher\": {\n",
    "                \"urls\": [\n",
    "                    \"https://medium.com/@ssafarveisi/stream-processing-using-apache-flink-70c5a990801a\",\n",
    "                    \"https://medium.com/@ssafarveisi/pyspark-stream-processing-on-k8s-using-stackable-data-platform-5695b0eafd6f\",\n",
    "                ],  # Replace these URLS with yours\n",
    "            },\n",
    "            \"pdf_converter\": {\n",
    "                \"sources\": [\"artifactory_for_poetry.pdf\"]\n",
    "            },  # Replace this PDF file with yours\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return document_store\n",
    "\n",
    "\n",
    "def create_rag_pipeline(document_store: QdrantDocumentStore) -> Pipeline:\n",
    "    \"\"\"\n",
    "    Creates a RAG pipeline using a persisted vector database.\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    document_store:\n",
    "        An instance of a document store\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    An instance of a Pipeline (RAG)\n",
    "    \"\"\"\n",
    "    # Create the prompt for the LLM (generative model)\n",
    "    prompt_template = \"\"\"\n",
    "    Answer the following question given the documents.\n",
    "    If the answer is not contained within the documents reply with 'no_answer'\n",
    "    Query: {{question}}\n",
    "    Documents:\n",
    "    {% for document in documents %}\n",
    "    {{document.content}}\n",
    "    {% endfor %}\n",
    "    \"\"\"\n",
    "\n",
    "    # Pipeline components for RAG\n",
    "    prompt_builder = PromptBuilder(template=prompt_template)\n",
    "    text_embedder = SentenceTransformersTextEmbedder(\n",
    "        model=\"BAAI/bge-small-en-v1.5\", device=ComponentDevice.from_str(\"cuda:0\")\n",
    "    )\n",
    "    retriever = QdrantEmbeddingRetriever(document_store)\n",
    "    llm = OpenAIGenerator(\n",
    "        model=\"gpt-4o-mini\", api_key=Secret.from_token(OPENAI_API_KEY)\n",
    "    )\n",
    "\n",
    "    ## Pipeline\n",
    "    rag_pipeline = Pipeline()\n",
    "\n",
    "    ## Adding components into the pipeline\n",
    "    rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "    rag_pipeline.add_component(\"retriever\", retriever)\n",
    "    rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "    rag_pipeline.add_component(\"llm\", llm)\n",
    "    rag_pipeline.add_component(\"answer_builder\", AnswerBuilder())\n",
    "\n",
    "    ## Pipeline connections\n",
    "    rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "    rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "    rag_pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "    rag_pipeline.connect(\"llm.replies\", \"answer_builder.replies\")\n",
    "    rag_pipeline.connect(\"llm.meta\", \"answer_builder.meta\")\n",
    "    rag_pipeline.connect(\"retriever\", \"answer_builder.documents\")\n",
    "\n",
    "    return rag_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38cff22487474384b184318f8faadf9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "document_store = create_vector_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store.count_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline = create_rag_pipeline(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ad68d9fee84e488b60b6c0768f5514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of Stackable that the author used is 22.11.\n"
     ]
    }
   ],
   "source": [
    "# Example question\n",
    "question = \"Which version of Stackable did the author use?\"\n",
    "\n",
    "response = rag_pipeline.run(\n",
    "    {\n",
    "        \"text_embedder\": {\"text\": question},\n",
    "        \"prompt_builder\": {\"question\": question},\n",
    "        \"answer_builder\": {\"query\": question},\n",
    "    },\n",
    ")\n",
    "\n",
    "print(response[\"answer_builder\"][\"answers\"][0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data frame is used to evaluate the retriever in the RAG pipeline.\n",
    "# Replace the questions with yours. You need to modify the source key as well.\n",
    "# The source key points to the actual source in which the relevant documents to the\n",
    "# question can be found and retrieved by the retriever.\n",
    "eval_data = pd.DataFrame(\n",
    "    {\n",
    "        \"question\": [\n",
    "            \"Which version of Stackable did the author use?\",\n",
    "            \"Which K8s operators did the author use to showcase pyspark stream processing?\",\n",
    "            \"Which mode did the author opt to deploy a Flink cluster on k8s?\",\n",
    "            \"How many task managers did the author select for the Flink cluster?\",\n",
    "            \"What is DEFAULT_CA_BUNDLE for poetry artifactory access?\",\n",
    "        ],\n",
    "        \"source\": [\n",
    "            [\n",
    "                \"https://medium.com/@ssafarveisi/pyspark-stream-processing-on-k8s-using-stackable-data-platform-5695b0eafd6f\"\n",
    "            ],\n",
    "            [\n",
    "                \"https://medium.com/@ssafarveisi/pyspark-stream-processing-on-k8s-using-stackable-data-platform-5695b0eafd6f\"\n",
    "            ],\n",
    "            [\n",
    "                \"https://medium.com/@ssafarveisi/stream-processing-using-apache-flink-70c5a990801a\"\n",
    "            ],\n",
    "            [\n",
    "                \"https://medium.com/@ssafarveisi/stream-processing-using-apache-flink-70c5a990801a\"\n",
    "            ],\n",
    "            [\"artifactory_for_poetry.pdf\"],\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/987346353460110895', creation_time=1724771462751, experiment_id='987346353460110895', last_update_time=1724771462751, lifecycle_stage='active', name='Evaluate RAG', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the mlflow experiment to which the mlflow runs are logged\n",
    "mlflow.set_experiment(\"Evaluate RAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_embedding():\n",
    "    \"\"\"Evaluates the retriever in the RAG pipeline\"\"\"\n",
    "\n",
    "    def extract_source(doc: Document) -> str:\n",
    "        if \"url\" in doc.meta:\n",
    "            return doc.meta[\"url\"]\n",
    "        elif \"file_path\" in doc.meta:\n",
    "            return doc.meta[\"file_path\"]\n",
    "        else:\n",
    "            raise KeyError(\"Neither 'url' nor 'file_path' exists in the metadata\")\n",
    "\n",
    "    def retrieve_doc_sources(question: str) -> List[str]:\n",
    "        response = rag_pipeline.run(\n",
    "            {\n",
    "                \"text_embedder\": {\"text\": question},\n",
    "                \"prompt_builder\": {\"question\": question},\n",
    "                \"answer_builder\": {\"query\": question},\n",
    "            }\n",
    "        )\n",
    "        docs = response[\"answer_builder\"][\"answers\"][0].documents\n",
    "        return [extract_source(doc) for doc in docs]\n",
    "\n",
    "    def retriever_model_function(question_df: pd.DataFrame) -> pd.Series:\n",
    "        return question_df[\"question\"].apply(retrieve_doc_sources)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        return mlflow.evaluate(\n",
    "            model=retriever_model_function,\n",
    "            data=eval_data,\n",
    "            model_type=\"retriever\",\n",
    "            targets=\"source\",\n",
    "            evaluators=\"default\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a68ceac463a43ba988a2562028ce491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9bcb8d2935a48d2a1490de3a339c6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4397b789a7084189927357f2aedffe06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b9efaee06f4708be76c7cd59e1756c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693956e8de414956b2033db05ef20d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = evaluate_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572270d710794f6bb15c41800be763c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results_of_retriever_df_bge_small_en = result.tables[\"eval_results_table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>source</th>\n",
       "      <th>outputs</th>\n",
       "      <th>precision_at_3/score</th>\n",
       "      <th>recall_at_3/score</th>\n",
       "      <th>ndcg_at_3/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which version of Stackable did the author use?</td>\n",
       "      <td>[https://medium.com/@ssafarveisi/pyspark-strea...</td>\n",
       "      <td>[https://medium.com/@ssafarveisi/pyspark-strea...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which K8s operators did the author use to show...</td>\n",
       "      <td>[https://medium.com/@ssafarveisi/pyspark-strea...</td>\n",
       "      <td>[https://medium.com/@ssafarveisi/pyspark-strea...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which mode did the author opt to deploy a Flin...</td>\n",
       "      <td>[https://medium.com/@ssafarveisi/stream-proces...</td>\n",
       "      <td>[https://medium.com/@ssafarveisi/stream-proces...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many task managers did the author select f...</td>\n",
       "      <td>[https://medium.com/@ssafarveisi/stream-proces...</td>\n",
       "      <td>[https://medium.com/@ssafarveisi/stream-proces...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is DEFAULT_CA_BUNDLE for poetry artifacto...</td>\n",
       "      <td>[artifactory_for_poetry.pdf]</td>\n",
       "      <td>[artifactory_for_poetry.pdf, artifactory_for_p...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0     Which version of Stackable did the author use?   \n",
       "1  Which K8s operators did the author use to show...   \n",
       "2  Which mode did the author opt to deploy a Flin...   \n",
       "3  How many task managers did the author select f...   \n",
       "4  What is DEFAULT_CA_BUNDLE for poetry artifacto...   \n",
       "\n",
       "                                              source  \\\n",
       "0  [https://medium.com/@ssafarveisi/pyspark-strea...   \n",
       "1  [https://medium.com/@ssafarveisi/pyspark-strea...   \n",
       "2  [https://medium.com/@ssafarveisi/stream-proces...   \n",
       "3  [https://medium.com/@ssafarveisi/stream-proces...   \n",
       "4                       [artifactory_for_poetry.pdf]   \n",
       "\n",
       "                                             outputs  precision_at_3/score  \\\n",
       "0  [https://medium.com/@ssafarveisi/pyspark-strea...              0.333333   \n",
       "1  [https://medium.com/@ssafarveisi/pyspark-strea...              0.666667   \n",
       "2  [https://medium.com/@ssafarveisi/stream-proces...              1.000000   \n",
       "3  [https://medium.com/@ssafarveisi/stream-proces...              1.000000   \n",
       "4  [artifactory_for_poetry.pdf, artifactory_for_p...              0.666667   \n",
       "\n",
       "   recall_at_3/score  ndcg_at_3/score  \n",
       "0                  1         1.000000  \n",
       "1                  1         0.919721  \n",
       "2                  1         1.000000  \n",
       "3                  1         1.000000  \n",
       "4                  1         1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(eval_results_of_retriever_df_bge_small_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe5b7da0c6546d78bd11206788a07f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>precision_at_3/score</th>\n",
       "      <th>recall_at_3/score</th>\n",
       "      <th>ndcg_at_3/score</th>\n",
       "      <th>source</th>\n",
       "      <th>outputs</th>\n",
       "      <th>precision_at_1/score</th>\n",
       "      <th>precision_at_2/score</th>\n",
       "      <th>recall_at_1/score</th>\n",
       "      <th>recall_at_2/score</th>\n",
       "      <th>ndcg_at_1/score</th>\n",
       "      <th>ndcg_at_2/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which version of Stackable did the author use?</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[https://medium.com/@ssafarveisi/pyspark-strea...</td>\n",
       "      <td>[https://medium.com/@ssafarveisi/pyspark-strea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which K8s operators did the author use to show...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919721</td>\n",
       "      <td>[https://medium.com/@ssafarveisi/pyspark-strea...</td>\n",
       "      <td>[https://medium.com/@ssafarveisi/pyspark-strea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which mode did the author opt to deploy a Flin...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[https://medium.com/@ssafarveisi/stream-proces...</td>\n",
       "      <td>[https://medium.com/@ssafarveisi/stream-proces...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many task managers did the author select f...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[https://medium.com/@ssafarveisi/stream-proces...</td>\n",
       "      <td>[https://medium.com/@ssafarveisi/stream-proces...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is DEFAULT_CA_BUNDLE for poetry artifacto...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[artifactory_for_poetry.pdf]</td>\n",
       "      <td>[artifactory_for_poetry.pdf, artifactory_for_p...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  precision_at_3/score  \\\n",
       "0     Which version of Stackable did the author use?              0.333333   \n",
       "1  Which K8s operators did the author use to show...              0.666667   \n",
       "2  Which mode did the author opt to deploy a Flin...              1.000000   \n",
       "3  How many task managers did the author select f...              1.000000   \n",
       "4  What is DEFAULT_CA_BUNDLE for poetry artifacto...              0.666667   \n",
       "\n",
       "   recall_at_3/score  ndcg_at_3/score  \\\n",
       "0                  1         1.000000   \n",
       "1                  1         0.919721   \n",
       "2                  1         1.000000   \n",
       "3                  1         1.000000   \n",
       "4                  1         1.000000   \n",
       "\n",
       "                                              source  \\\n",
       "0  [https://medium.com/@ssafarveisi/pyspark-strea...   \n",
       "1  [https://medium.com/@ssafarveisi/pyspark-strea...   \n",
       "2  [https://medium.com/@ssafarveisi/stream-proces...   \n",
       "3  [https://medium.com/@ssafarveisi/stream-proces...   \n",
       "4                       [artifactory_for_poetry.pdf]   \n",
       "\n",
       "                                             outputs  precision_at_1/score  \\\n",
       "0  [https://medium.com/@ssafarveisi/pyspark-strea...                     1   \n",
       "1  [https://medium.com/@ssafarveisi/pyspark-strea...                     1   \n",
       "2  [https://medium.com/@ssafarveisi/stream-proces...                     1   \n",
       "3  [https://medium.com/@ssafarveisi/stream-proces...                     1   \n",
       "4  [artifactory_for_poetry.pdf, artifactory_for_p...                     1   \n",
       "\n",
       "   precision_at_2/score  recall_at_1/score  recall_at_2/score  \\\n",
       "0                   0.5                  1                  1   \n",
       "1                   0.5                  1                  1   \n",
       "2                   1.0                  1                  1   \n",
       "3                   1.0                  1                  1   \n",
       "4                   1.0                  1                  1   \n",
       "\n",
       "   ndcg_at_1/score  ndcg_at_2/score  \n",
       "0                1                1  \n",
       "1                1                1  \n",
       "2                1                1  \n",
       "3                1                1  \n",
       "4                1                1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    # Suppress the warning 'Inferred schema contains integer column(s)...'\n",
    "    warnings.simplefilter(\"ignore\", UserWarning)\n",
    "    # Evaluate different top K strategy with Mlflow\n",
    "    with mlflow.start_run() as run:\n",
    "        evaluate_results = mlflow.evaluate(\n",
    "            data=eval_results_of_retriever_df_bge_small_en,\n",
    "            targets=\"source\",\n",
    "            predictions=\"outputs\",\n",
    "            evaluators=\"default\",\n",
    "            extra_metrics=[\n",
    "                mlflow.metrics.precision_at_k(1),\n",
    "                mlflow.metrics.precision_at_k(2),\n",
    "                mlflow.metrics.precision_at_k(3),\n",
    "                mlflow.metrics.recall_at_k(1),\n",
    "                mlflow.metrics.recall_at_k(2),\n",
    "                mlflow.metrics.recall_at_k(3),\n",
    "                mlflow.metrics.ndcg_at_k(1),\n",
    "                mlflow.metrics.ndcg_at_k(2),\n",
    "                mlflow.metrics.ndcg_at_k(3),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    display(evaluate_results.tables[\"eval_results_table\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
